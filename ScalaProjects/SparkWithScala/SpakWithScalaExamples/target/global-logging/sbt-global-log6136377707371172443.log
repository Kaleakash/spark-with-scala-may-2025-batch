[0m[[0m[0mdebug[0m] [0m[0m> Exec(compile, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / compile[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 2 Scala sources to /home/labuser/Desktop/spark-with-scala-may-2025-batch/ScalaProjects/SparkWithScala/SpakWithScalaExamples/target/scala-2.13/classes ...[0m
[0m[[0m[31merror[0m] [0m[0m/home/labuser/Desktop/spark-with-scala-may-2025-batch/ScalaProjects/SparkWithScala/SpakWithScalaExamples/src/main/scala/com/EmployeeRDD.scala:16:58: not found: type !=[0m
[0m[[0m[31merror[0m] [0m[0m    val employeeData = employeeRawData.filter((l:Any => l!= header));[0m
[0m[[0m[31merror[0m] [0m[0m                                                         ^[0m
[0m[[0m[31merror[0m] [0m[0m/home/labuser/Desktop/spark-with-scala-may-2025-batch/ScalaProjects/SparkWithScala/SpakWithScalaExamples/src/main/scala/com/EmployeeRDD.scala:16:48: not found: value l[0m
[0m[[0m[31merror[0m] [0m[0m    val employeeData = employeeRawData.filter((l:Any => l!= header));[0m
[0m[[0m[31merror[0m] [0m[0m                                               ^[0m
[0m[[0m[31merror[0m] [0m[0mtwo errors found[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mcompileIncremental[0m) Compilation failed[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 1 s, completed May 13, 2025 9:57:48 AM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(idea-shell, None, None)[0m
